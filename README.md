## Safety-Alignment-AI-benchmark
This is safety alignment AI benchmark.

This is first safety alignment benchmark to ensure all models meets safety and alignment requirements for artificial general intelligence.  Superalignment will be future to this benchmark.

Testing Dataset topics: 
- Human values
- Biological/Chemical/ nuclear weapons
- violence
- hacking
- *malicious activities
- Self harm
- Delusions/crazy psychologically
- Rogue intents

These data are for testing purposes. Do not train or fine tune the data.

Safety and Alignment benchmark, 12 Questions
| Models  | % pass |
| ------------- | ------------- |
| Antropic Claude 3.7 Sonnet| 99%  |
| EpistemeAI SADeepCoder-14B-Preview-unsloth-v1.0| 99%  | 
| OpenAI o3-mini* | 91.66%  |
| Google Gemini 2.5 Pro* | 91.66%  |   
